<!DOCTYPE html>
<html lang="hi">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>VR Flow: Intro → Scene 1 → Scene 2</title>

    <!-- Suppress favicon 404 on GitHub Pages -->
    <link rel="icon" href="data:,">

    <!-- A-Frame -->
    <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>

    <style>
      body { margin: 0; background:#000; }
      #versionTag { position: fixed; top: 6px; left: 10px; z-index: 9999; font: 12px/1 monospace; color:#0f0; opacity:.8; }
      /* Local TTF for Canvas text (proper Indic shaping) */
      @font-face {
        font-family: 'NotoDev';
        src: url('./assets/NotoSansDevanagari-Regular.ttf') format('truetype');
        font-weight: normal;
        font-style: normal;
        font-display: swap;
      }
    </style>

    <script>
      // ---------- Face the camera (billboard) ----------
      AFRAME.registerComponent('face-camera', {
        schema: { onlyY: {type: 'boolean', default: true} },
        init() {
          this.cam = document.querySelector('#camera');
          this.tmpCam = new THREE.Vector3();
          this.tmpObj = new THREE.Vector3();
        },
        tick() {
          if (!this.cam) return;
          const obj = this.el.object3D;
          this.cam.object3D.getWorldPosition(this.tmpCam);
          obj.getWorldPosition(this.tmpObj);
          if (this.data.onlyY) {
            const target = this.tmpCam.clone();
            target.y = this.tmpObj.y;
            obj.lookAt(target);
          } else {
            obj.lookAt(this.tmpCam);
          }
        }
      });

      // ---------- Canvas Text (Unicode-safe, incl. i-matra) ----------
      // Draws to an offscreen canvas and maps it to a THREE.CanvasTexture.
      AFRAME.registerComponent('canvas-text', {
        schema: {
          value:       {type: 'string',  default: 'पाठ'},
          width:       {type: 'number',  default: 1.2},   // world width (m)
          maxWidthPx:  {type: 'int',     default: 1024},  // wrap width (px)
          fontFamily:  {type: 'string',  default: 'NotoDev'},
          fontSize:    {type: 'int',     default: 64},    // px
          lineHeight:  {type: 'number',  default: 1.25},
          color:       {type: 'string',  default: '#FFFFFF'},
          bg:          {type: 'string',  default: 'transparent'}, // e.g., rgba(0,0,0,0.35)
          paddingPx:   {type: 'int',     default: 16},
          align:       {type: 'string',  default: 'center'} // left|center|right
        },
        init() {
          this.canvas = document.createElement('canvas');
          this.canvas.width = 4; this.canvas.height = 4; // never 0×0
          this.ctx = this.canvas.getContext('2d');

          this.texture = new THREE.CanvasTexture(this.canvas);
          this.texture.generateMipmaps = false;
          this.texture.minFilter = THREE.LinearFilter;
          this.texture.magFilter = THREE.LinearFilter;
          this.texture.wrapS = THREE.ClampToEdgeWrapping;
          this.texture.wrapT = THREE.ClampToEdgeWrapping;
          this.texture.needsUpdate = true;

          if (!this.el.getAttribute('geometry')) {
            this.el.setAttribute('geometry', 'primitive: plane; width: 1; height: 0.5');
          }

          const attach = () => {
            const mesh = this.el.getObject3D('mesh');
            if (!mesh) return;
            mesh.material = new THREE.MeshBasicMaterial({
              map: this.texture,
              transparent: true,
              color: 0xffffff,
              depthTest: true,
              depthWrite: false,
              side: THREE.DoubleSide
            });
            mesh.material.needsUpdate = true;
            this._ensureFont().then(() => this._draw());
          };
          if (this.el.getObject3D('mesh')) attach();
          else this.el.addEventListener('object3dset', e => { if (e.detail.type === 'mesh') attach(); });
        },
        update() { this._ensureFont().then(() => this._draw()); },
        _ensureFont() {
          if (document.fonts && document.fonts.load) {
            return document.fonts.load(`16px "${this.data.fontFamily}"`).catch(()=>{});
          }
          return Promise.resolve();
        },
        _wrapLines(text, maxWidthPx) {
          const ctx = this.ctx, words = text.split(/\s+/), lines = [];
          let line = '';
          for (let i=0;i<words.length;i++){
            const test = line ? (line + ' ' + words[i]) : words[i];
            if (ctx.measureText(test).width > maxWidthPx && line) { lines.push(line); line = words[i]; }
            else { line = test; }
          }
          if (line) lines.push(line);
          return lines;
        },
        _draw() {
          const d = this.data, ctx = this.ctx;
          const dpr = Math.max(1, Math.min(2, window.devicePixelRatio || 1));

          ctx.font = `${d.fontSize * dpr}px "${d.fontFamily}"`;
          ctx.textBaseline = 'alphabetic';
          ctx.fillStyle = d.color;

          const padding = d.paddingPx * dpr;
          const maxW = d.maxWidthPx * dpr;

          const lines = [];
          d.value.split('\n').forEach(para => {
            if (para === '') { lines.push(''); return; }
            this._wrapLines(para, maxW).forEach(l => lines.push(l));
          });

          const lh = d.fontSize * d.lineHeight * dpr;
          const textHeight = Math.max(lh, lines.length * lh);
          const canvasW = Math.max(4, Math.ceil(maxW + padding * 2));
          const canvasH = Math.max(4, Math.ceil(textHeight + padding * 2));

          if (this.canvas.width !== canvasW || this.canvas.height !== canvasH) {
            this.canvas.width = canvasW; this.canvas.height = canvasH;
          }

          ctx.clearRect(0, 0, canvasW, canvasH);
          if (d.bg && d.bg !== 'transparent') {
            ctx.fillStyle = d.bg; ctx.fillRect(0, 0, canvasW, canvasH); ctx.fillStyle = d.color;
          }

          if (d.align === 'left') ctx.textAlign = 'left';
          else if (d.align === 'right') ctx.textAlign = 'right';
          else ctx.textAlign = 'center';

          const x = d.align === 'left' ? padding : d.align === 'right' ? (canvasW - padding) : (canvasW / 2);
          let y = padding + (d.fontSize * dpr);
          for (const line of lines) { ctx.fillText(line, x, y); y += lh; }

          this.texture.needsUpdate = true;

          // Fit plane to canvas aspect at desired world width
          const aspect = canvasH / canvasW;
          const planeW = d.width;
          const planeH = d.width * aspect;
          this.el.setAttribute('geometry', `primitive: plane; width: ${planeW}; height: ${planeH}`);
        }
      });
    </script>
  </head>

  <body>
    <div id="versionTag">Code Version: v2.3-gh-pages-safe</div>

    <a-scene renderer="colorManagement: true; antialias: true" background="color: #000">
      <a-assets id="assets" timeout="60000">
        <!-- Images -->
        <img id="introBg" src="./assets/intro.png" />
        <img id="scene1"  src="./assets/Scene_1.jpg" />
        <img id="scene2"  src="./assets/Scene_2.jpg" />

        <!-- Audio (relative paths for GitHub Pages) -->
        <audio id="intro" src="./assets/intro.mp3" preload="auto" autoplay="true"></audio>
        <audio id="a1" src="./assets/Audio_1.mp3" preload="auto"></audio>
        <audio id="a2" src="./assets/Audio_2.mp3" preload="auto"></audio>
        <audio id="a3" src="./assets/Audio_3.mp3" preload="auto"></audio>
        <audio id="a4" src="./assets/Audio_4.mp3" preload="auto"></audio>
        <audio id="a5" src="./assets/Audio_5.mp3" preload="auto"></audio>

        <!-- Videos -->
        <video id="v1" src="./assets/Video_1.mp4" preload="auto" playsinline webkit-playsinline></video>
        <video id="v2" src="./assets/Video_2.mp4" preload="auto" playsinline webkit-playsinline></video>
        <video id="v3" src="./assets/Video_3.mp4" preload="auto" playsinline webkit-playsinline></video>
        <video id="v4" src="./assets/Video_4.mp4" preload="auto" playsinline webkit-playsinline></video>
      </a-assets>

      <!-- Camera + cursors -->
      <a-entity id="rig">
        <a-entity id="camera" camera wasd-controls look-controls position="0 1.6 0">
          <!-- Gaze cursor (fusing) -->
          <a-entity id="cursor"
            cursor="rayOrigin: entity; fuse: true; fuseTimeout: 1200"
            raycaster="objects: .interactable"
            position="0 0 -1"
            geometry="primitive: ring; radiusInner: 0.01; radiusOuter: 0.015"
            material="shader: flat; color: white; opacity: 0.9"></a-entity>

          <!-- Optional mouse cursor (kept invisible but active for desktop) -->
          <a-entity cursor="rayOrigin: mouse" raycaster="objects: .interactable" visible="false"></a-entity>
        </a-entity>
      </a-entity>

      <!-- Background -->
      <a-sky id="bg" radius="500" material="shader: flat; side: back; src: #introBg"></a-sky>

      <!-- Enter button -->
      <a-plane id="enterBtn"
               position="-1 1.3 -2" width="0.8" height="0.3"
               material="color: #666; opacity: 1; shader: flat"
               face-camera>
        <a-entity position="0 0 0.01" face-camera
                  canvas-text="value: आगे बढ़ें; width: 0.75; fontSize: 72; align: center;"></a-entity>
      </a-plane>

      <!-- Wait text -->
      <a-entity id="waitText" position="-1 1.8 -2" visible="true" face-camera
                canvas-text="value: कृपया ऑडियो पूरा होने तक प्रतीक्षा करें.; width: 2; fontSize: 60; align: center;"></a-entity>

      <!-- Videos (larger; all face camera) -->
      <a-video id="vp1" position="-1.2 1.35 -2" width="3.6" height="2.025" src="#v1"
               material="shader: flat; opacity: 0" visible="false" face-camera></a-video>

      <a-video id="vp2" position="0.5 1.35 -2"  width="3.6" height="2.025" src="#v2"
               material="shader: flat; opacity: 0" visible="false" face-camera></a-video>

      <a-video id="vp3" position="1.9 1.15 -2.2" width="3.6" height="2.025"  src="#v3"
               material="shader: flat; opacity: 0" visible="false" face-camera></a-video>

      <a-video id="vp4" position="-2.0 1.1 -2.4" width="3.6" height="2.025"  src="#v4"
               material="shader: flat; opacity: 0" visible="false" face-camera></a-video>

      <!-- Thanks text -->
      <a-entity id="thanksText" position="0 1.8 -2" visible="false" face-camera
                canvas-text="value: धन्यवाद; width: 2; fontSize: 72; align: center;"></a-entity>
    </a-scene>

    <script>
      // ===== Helpers =====
      function waitForEnded(mediaEl) {
        return new Promise(res => {
          const onEnd = () => { mediaEl.removeEventListener('ended', onEnd); res(); };
          mediaEl.addEventListener('ended', onEnd);
        });
      }
      const sleep = (ms) => new Promise(r => setTimeout(r, ms));
      function fadeIn(el, ms = 1000) {
        el.setAttribute('visible', true);
        el.setAttribute('animation__fadein', { property: 'material.opacity', from: 0, to: 1, dur: ms, easing: 'easeInOutQuad' });
      }
      function fadeOut(el, ms = 1000) {
        const current = (el.getAttribute('material') || {}).opacity || 1;
        el.setAttribute('animation__fadeout', { property: 'material.opacity', from: current, to: 0, dur: ms, easing: 'easeInOutQuad' });
        setTimeout(() => el.setAttribute('visible', false), ms);
      }
      function setButtonEnabled(btn, enabled) {
        btn.setAttribute('material', 'color', enabled ? '#28a745' : '#666');
      }
      function setButtonInteractive(btn, on) {
        const cls = btn.getAttribute('class') || '';
        const has = cls.split(/\s+/).includes('interactable');
        if (on && !has) btn.setAttribute('class', (cls + ' interactable').trim());
        if (!on && has) btn.setAttribute('class', cls.replace(/\binteractable\b/, '').trim());
      }

      // ===== Init (GitHub Pages–safe autoplay logic) =====
      (function(){
        function initScene(){
          const enterBtn = document.getElementById('enterBtn');
          const waitText = document.getElementById('waitText');
          const intro = document.getElementById('intro');

          let enterArmed = false;

          // Start disabled: visible but not interactable
          waitText.setAttribute('visible', true);
          setButtonEnabled(enterBtn, false);
          setButtonInteractive(enterBtn, false);

          // Try autoplay (often blocked on GH Pages)
          intro.play().catch(()=>{});

          // If no progress shortly, allow a user gesture to start audio
          const AUTOPLAY_CHECK_MS = 1500;
          setTimeout(() => {
            if (!enterArmed && intro.currentTime === 0) {
              waitText.setAttribute('canvas-text',
                'value: कृपया ऑडियो शुरू करने के लिए टैप/क्लिक करें.; width: 2.2; fontSize: 60; align: center;');
              setButtonInteractive(enterBtn, true);
              setButtonEnabled(enterBtn, true); // give visual hint
            }
          }, AUTOPLAY_CHECK_MS);

          // When intro ends, arm the button and freeze intro
          intro.addEventListener('ended', () => {
            try { intro.pause(); intro.muted = true; intro.currentTime = intro.duration || intro.currentTime; } catch(e){}
            waitText.setAttribute('visible', false);
            setButtonInteractive(enterBtn, true);
            setButtonEnabled(enterBtn, true);
            enterArmed = true;
          }, { once: true });

          // If intro fails to load, don't deadlock
          intro.addEventListener('error', () => {
            setButtonInteractive(enterBtn, true);
            setButtonEnabled(enterBtn, true);
            enterArmed = true;
            waitText.setAttribute('canvas-text',
              'value: ऑडियो लोड नहीं हुआ। आगे बढ़ें बटन दबाएँ.; width: 2.2; fontSize: 60; align: center; color: #FFCC00;');
          }, { once: true });

          // Unified handler for click/gaze fuse
          const activate = () => {
            // Before armed: first click/fuse should just try to start intro
            if (!enterArmed) {
              if (intro.paused) { intro.play().catch(()=>{}); }
              return;
            }
            // Armed: proceed (never touch intro again)
            startScene1();
            enterBtn.setAttribute('visible', false);
          };

          enterBtn.addEventListener('click', activate);
          enterBtn.addEventListener('mousedown', activate);
        }

        const sceneEl = document.querySelector('a-scene');
        if (sceneEl) {
          if (sceneEl.hasLoaded) initScene();
          else sceneEl.addEventListener('loaded', initScene, { once: true });
        } else {
          window.addEventListener('load', initScene, { once: true });
        }
      })();

      // ===== Flow =====
      async function startScene1() {
        const bg = document.getElementById('bg');
        const thanksText = document.getElementById('thanksText');
        const a1 = document.getElementById('a1');
        const a2 = document.getElementById('a2');
        const a3 = document.getElementById('a3');
        const a4 = document.getElementById('a4');
        const a5 = document.getElementById('a5');
        const v1 = document.getElementById('v1');
        const v2 = document.getElementById('v2');
        const v3 = document.getElementById('v3');
        const v4 = document.getElementById('v4');
        const vp1 = document.getElementById('vp1');
        const vp2 = document.getElementById('vp2');
        const vp3 = document.getElementById('vp3');
        const vp4 = document.getElementById('vp4');
        const fadeCfg = { inMs: 1000, outMs: 1000, delayThumbMs: 2200 };

        // Safety: ensure intro is silent now
        const intro = document.getElementById('intro');
        try { intro.pause(); intro.muted = true; } catch(e){}

        bg.setAttribute('material', 'shader: flat; side: back; src: #scene1');

        await playSegment(a1, v1, vp1, fadeCfg);
        await playSegment(a2, v2, vp2, fadeCfg);
        await playSegment(a3, v3, vp3, fadeCfg);
        await playSegment(a4, v4, vp4, fadeCfg);

        bg.setAttribute('material', 'shader: flat; side: back; src: #scene2');
        thanksText.setAttribute('visible', true);
        a5.play();
      }

      // ===== Segment player =====
      async function playSegment(audioEl, videoEl, videoSurface, fadeCfg) {
        try {
          try { videoEl.pause(); } catch(e){}
          try { videoEl.currentTime = 0; } catch(e){}
          try { videoEl.load(); } catch(e){}

          await new Promise(resolve => {
            if (videoEl.readyState >= 2) return resolve();
            const onReady = () => { cleanup(); resolve(); };
            const cleanup = () => {
              videoEl.removeEventListener('loadeddata', onReady);
              videoEl.removeEventListener('canplay', onReady);
              videoEl.removeEventListener('loadedmetadata', onReady);
            };
            videoEl.addEventListener('loadeddata', onReady, { once: true });
            videoEl.addEventListener('canplay', onReady, { once: true });
            videoEl.addEventListener('loadedmetadata', onReady, { once: true });
          });

          // Show surface, prime a frame during narration
          videoSurface.setAttribute('visible', true);
          videoSurface.setAttribute('material', 'opacity', 0);
          try { videoEl.muted = true; await videoEl.play(); await sleep(80); videoEl.pause(); } catch(e){}

          // Start narration and show preview
          await audioEl.play();
          await sleep(fadeCfg.delayThumbMs);
          fadeIn(videoSurface, fadeCfg.inMs);

          // After narration, unmute and play clip
          await waitForEnded(audioEl);
          try { videoEl.muted = false; videoEl.volume = 1.0; } catch(e){}
          try { await videoEl.play(); } catch(e) { console.warn('Video play rejected', e); }
          await waitForEnded(videoEl);

          // Fade out & hide
          fadeOut(videoSurface, fadeCfg.outMs);
          await sleep(fadeCfg.outMs + 50);
          videoSurface.setAttribute('visible', false);
        } catch(err) {
          console.error('playSegment error', err);
        }
      }
    </script>
  </body>
</html>
